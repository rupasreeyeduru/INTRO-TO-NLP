# -*- coding: utf-8 -*-
"""nlm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17QJeaFEqvBQbarAPhZePMUmcUVaafmow
"""

import torch
from torch import nn,optim
import time
from math import inf,log,exp
from torch.utils.data import Dataset
from google.colab import drive
from torch.utils.data import DataLoader
from torch.nn.functional import softmax
drive.mount('/content/drive')
import numpy as np
import sys


device = "cuda" if torch.cuda.is_available() else "cpu"
print("Using {device}",device)

path=sys.argv[1]

import re

def replaceHashtags(txt):
    return re.sub(r'\#\w+', '<HASH>', txt)

def replaceMentions(txt):
    return re.sub(r'@\w+', '<MENTION>', txt)

def replaceURL(txt):
    return re.sub(r'(https?://|www.)[\w.-]+\.[\w]+\S+','<URL>',txt)

def seperate_hyphen(txt):
    return re.sub(r'([a-zA-Z]+)-([a-zA-Z]+)', r'\1 \2', txt)

def remove_underscore(txt):
    t=re.sub(r'\b(\_)(\w+)(\_)\b',r'\2',txt)
    t=re.sub(r'\b(\_)(\w+)\b',r'\2',t)
    t=re.sub(r'\b(\w+)(\_)\b',r'\2',t)
    return t

def remove_quot(txt):
    return re.sub(r'\"',r' " ',txt)

def remove_brac(txt):
    txt=re.sub(r'\(',r'( ',txt)
    txt=re.sub(r'\)',r' )',txt)
    txt=re.sub(r'\[',r'[ ',txt)
    txt=re.sub(r'\]',r' ]',txt)
    return txt

def remove_apos(txt):
    return  re.sub(r"([a-zA-Z]+)(\')([s])",r"\1 \2 \3",txt)
def remove___(txt):
    return re.sub(r'([\-+])',r' \1 ',txt)
def remove_punc(txt):
    return re.sub(r'\b(\w+)(\.|\,|\?|\!|\;|\:)',r'\1 \2',txt)

def remove_whitespace(txt):
    txt=re.sub(r'\n+','\n',txt)
    txt=re.sub(r'\s+',' ',txt)
    return txt

def replace_no(txt):    
    txt=re.sub(r'\d+',r'<NUM>',txt)
    txt=re.sub(r'(?:[\d]\.)+',r'<NUM>',txt)
    txt=re.sub(r'(-+)',r' ',txt)
    return txt

def mr_mrs(txt):
    txt=re.sub(r'(m|M)r \.',r'\1r',txt)
    txt=re.sub(r'(m|M)rs \.',r'\1rs',txt)
    return txt
def handle_abbr(txt):
    return re.sub(r'(?:[A-Za-z]\.)+',r'<abb>',txt )

def tokenize(txt):
    txt=remove_quot(txt)
    txt=replace_no(txt)
    txt=replaceHashtags(txt)
    txt=replaceMentions(txt)
    txt=remove_brac(txt)
    txt=replaceURL(txt)
    txt=seperate_hyphen(txt)
    txt=remove_punc(txt)
    txt=remove_underscore(txt)
    txt=remove_apos(txt)
    txt=txt.lower()
    txt=remove_whitespace(txt)
    txt=mr_mrs(txt)
    txt=handle_abbr(txt)
    return txt

class Model(nn.Module):
    def __init__(self, train):
        super(Model, self).__init__()
        self.n_layers = 1
        self.hidden_size = 128
        self.embed_dim = 100
        self.device="cuda" if torch.cuda.is_available() else "cpu"
        self.embedding = nn.Embedding(num_embeddings=train.vocab_size, embedding_dim=self.embed_dim,device=self.device)
        self.lstm = nn.LSTM(input_size=self.embed_dim, num_layers=self.n_layers, hidden_size=self.hidden_size ,batch_first=False,device=self.device)
        self.fc = nn.Linear(self.hidden_size, train.vocab_size,device=self.device) 
        self.to(self.device)
       

    def forward(self, x, prev):
        input = self.embedding(x)
        output, curr = self.lstm(input, prev)
        output= self.fc(output)
        
        return output,curr

class DataSet(Dataset):
     def __init__(self, f,seq_length):
       self.fil=f
       self.vocab=[]
       
       self.data=self.load_data()
       self.words_to_indices = self.convert_to_indices()
       self.indices=[self.words_to_indices[w] for w in self.data]
       self.seq_length=seq_length
       self.device="cuda" if torch.cuda.is_available() else "cpu"
       self.vocab_size=len(self.vocab)
       
       
     def load_data(self):
           data=[]
           fre={}
           fre['<s>']=0
           fre['</s>']=0
           print(self.fil)
           fp=open(self.fil,"r")
           
           txt=fp.readlines()
           for lines in txt:
              lines=lines.split(" ")
              data+=lines
              data+='<s>'
              data+='</s>'
              for w in lines:
                if(fre.get(w,0)==0):
                      fre[w]=1
                else:
                    fre[w]+=1
              fre['<s>']+=1
              fre['</s>']+=1
           for i in range(len(data)):
              # print(data[i],fre.get(data[i],0))
              if fre.get(data[i],0) <3:
                    data[i]='<UNK>'
           self.vocab=set(data)
           return data
 
     def convert_to_indices(self):
            return {word:index for index,word in enumerate(self.vocab)}

     def __len__(self):
        return len(self.data)-self.seq_length

      
     def __getitem__(self,index):
           return torch.tensor(self.indices[index:index+self.seq_length+1])

def detach(states):
    return [state.detach() for state in states] 

def initstate(model,seq_length):
     return [torch.zeros(model.n_layers,seq_length,model.hidden_size,device=model.device),torch.zeros(model.n_layers,seq_length,model.hidden_size,device=model.device)]

def run_epoch(model,dataloader,criterion,optimiser,batch_size):
      states=initstate(model,4)
      total_epoch_loss=0
      for batch, X in enumerate(dataloader):
            x=X[:,:-1].to(model.device)
            y=X[:,1:].to(model.device)
            optimiser.zero_grad()
            y_pred, states = model(x, states)
        
            loss = criterion(y_pred.transpose(1, 2), y)

            states=detach(states)

            loss.backward()
            optimiser.step()

            total_epoch_loss += loss.item()
      
      return total_epoch_loss/len(dataloader)



def train(dataset, model, batch_size):
   
    model.train()
    
    
    learning_rate = 0.01
    dataloader = DataLoader(dataset, batch_size=4)
    criterion = nn.CrossEntropyLoss()
    optimiser = optim.Adam(model.parameters(), lr=learning_rate)
    prev_loss=inf
    for epoch in range(5):
           curr_loss=run_epoch(model,dataloader,criterion,optimiser,batch_size=4)
           diff=abs(curr_loss-prev_loss)
           print(diff)
           if(diff<0.01):
             return model
           prev_loss=curr_loss
    return model

        

        
def perplexity(model,sent):
     model.eval()
     x_=[]
     lprob=[]
     for i in range(0,len(sent)):
           x_.append(sent[i])
           x=torch.tensor([x_.copy()]).to(model.device)
           states=initstate(model,i+1)
           y,states=model(x,states)
           prob_dist=softmax(y[0][-1],dim=0).to('cpu').detach().numpy()
          
           lp=(prob_dist[sent[i]])
           lprob.append(lp)
    #  print(lprob)
     try:
         score=exp(-1*sum(lprob)/len(sent))
     except:
       return inf
     return score

def perplex_file(test,train,model,dataset,outputname):
    dic=dataset.words_to_indices
    with open(outputname+"_test-perplexity.txt", "w") as fp:
        for sentence in test:
          sent=[]
          cnt=0
          tot=0
          for w in sentence:
                if w not in dataset.vocab:
                      sent.append(dic['<UNK>'])
                else:
                      sent.append(dic[w])
          
          score=perplexity(model,sent)
          if score!=inf:
             tot+=score
             cnt+=1
          wr=" ".join(sentence)+'\t'+str(score)+'\n'
          fp.write(wr)
        fp.seek(0,0)
        fp.write(str(tot/cnt)+'\n')

    with open(outputname+"_train-perplexity.txt", "w") as fp:
        for sentence in train:
          sent=[]
          cnt=0
          tot=0
          for w in sentence:
                if w not in dataset.vocab:
                      sent.append(dic['<UNK>'])
                else:
                      sent.append(dic[w])
          score=perplexity(model,sent)
          if score!=inf:
            tot+=score
            cnt+=1
          wr=" ".join(sentence)+'\t'+str(score)+'\n'
          fp.write(wr)
        fp.seek(0,0)
        fp.write(str(tot/cnt)+'\n')

import random
# data1=open("/content/drive/MyDrive/corpus1.txt","r").read()
# data2=open("/content/drive/MyDrive/corpus2.txt","r").read()


# txt=tokenize(data1)
# txt= re.split(r'[.|;]', txt)
# res=[]
# for x in txt:
#     y=x.split(" ")
#     if(y[0]==""):
#             y=y[1:]
#             res.append(y)
    
# random.shuffle(res)
# test1=res[:1000]
# train1=res[1000:]


# with open("/content/drive/MyDrive/train1.txt","w") as fp:
#       for sent in train1:
#          for w in sent:
#             fp.write(w)
#             fp.write(" ")
#          fp.write('\n')

# txt=tokenize(data2)
# txt= re.split(r'[.|;]', txt)
# res=[]
# for x in txt:
#     y=x.split(" ")
#     if(y[0]==""):
#             y=y[1:]
#             res.append(y)
    
# random.shuffle(res)
# test2=res[:1000]
# train2=res[1000:]
# with open("/content/drive/MyDrive/train2.txt","w") as fp:
#       for sent in train2:
#          for w in sent:
#              fp.write(w)
#              fp.write(" ")
#          fp.write('\n')







# model=train(TRAIN,model,4)

# TRAIN1=DataSet("/content/drive/MyDrive/train1.txt",4)  
# TRAIN2=DataSet("/content/drive/MyDrive/train2.txt",4) 

# dataload1 = DataLoader(TRAIN1, batch_size=4, shuffle=True)
# dataload2 = DataLoader(TRAIN2, batch_size=4, shuffle=True)
# model1=Model(TRAIN1)
# model2=Model(TRAIN2)

# model1=train(TRAIN1,model1,4)
# torch.save(model1.state_dict(),"/content/drive/My Drive/m1.pth")

# model2=train(TRAIN2,model2,4)
# torch.save(model2.state_dict(),"/content/drive/My Drive/m2.pth")

# perplex_file(test1,train1,model1,TRAIN1,"/content/drive/My Drive/2020101097_LM5")
# perplex_file(test2,train2,model2,TRAIN2,"/content/drive/My Drive/2020101097_LM6")

in_path=sys.argv[1]

model=torch.load(in_path)
sentence = input("Input Sentence: ")
def modify_sentence(sentence):
    sentence=tokenize(sentence).split(" ")
    if sentence[0]=='':
        sentence=sentence[1:]
    if sentence[-1]=='':
        sentence=sentence[:-1]
    sent=[]
    dic=TRAIN1.words_to_indices
    for w in sentence:
          if w not in TRAIN1.vocab:
                sent.append(dic['<UNK>'])
          else:
              sent.append(dic[w])
    return sent

m_state_dict = torch.load(in_path)
train_path='./models/train1.txt'
TRAIN1=DataSet(train_path,4)
model = Model(TRAIN1)
model.load_state_dict(m_state_dict)
print(perplexity(model,modify_sentence(sentence)))